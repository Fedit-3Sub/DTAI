{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.model.model import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/merged_df.csv\") \n",
    "df = df[df[\"date_time\"]>\"2023-08-25 00:00:00\"] # 기상데이터가 있는 기간부터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 처리 (pm10, pm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]/tmp/ipykernel_3632327/3269961591.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"pm10_value\"] = temp_df['pm10_value'].fillna((temp_df[\"pm10_value\"].ffill()+\\\n",
      "/tmp/ipykernel_3632327/3269961591.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"pm25_value\"] = temp_df['pm25_value'].fillna((temp_df[\"pm25_value\"].ffill()+\\\n",
      "100%|██████████| 12/12 [00:00<00:00, 312.92it/s]\n"
     ]
    }
   ],
   "source": [
    "pm10_lst = []\n",
    "pm25_lst = []\n",
    "for pos_num in tqdm(range(1,13)):\n",
    "    temp_df = df[df[\"measure_position_id\"]==pos_num] # position number에 해당하는 데이터프레임\n",
    "\n",
    "    # 결측치는 앞뒤 비결측치 값의 평균으로 지정\n",
    "    temp_df[\"pm10_value\"] = temp_df['pm10_value'].fillna((temp_df[\"pm10_value\"].ffill()+\\\n",
    "                                                        temp_df[\"pm10_value\"].bfill())/2)\n",
    "    temp_df[\"pm25_value\"] = temp_df['pm25_value'].fillna((temp_df[\"pm25_value\"].ffill()+\\\n",
    "                                                        temp_df[\"pm25_value\"].bfill())/2)\n",
    "    pm10 = list(temp_df[\"pm10_value\"].values)\n",
    "    pm25 = list(temp_df[\"pm25_value\"].values)\n",
    "    pm10_lst.append(pm10)\n",
    "    pm25_lst.append(pm25)\n",
    "\n",
    "# 길이에 맞게 자름\n",
    "pm10_min_len = min(list(map(lambda x:len(x),pm10_lst)))\n",
    "pm25_min_len = min(list(map(lambda x:len(x),pm25_lst)))\n",
    "pm10_lst = list(map(lambda x:x[:pm10_min_len],pm10_lst))\n",
    "pm25_lst = list(map(lambda x:x[:pm25_min_len],pm25_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기상데이터 전처리후 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3588172/1926589154.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[strname]=temp_df[strname].fillna((temp_df[strname].ffill()+\\\n"
     ]
    }
   ],
   "source": [
    "temp_df = df[df[\"measure_position_id\"]==1.0]\n",
    "for strname in [\"precipitation_one_hour\",\"humidity\",\"temperature\",\"wind_speed\"]:\n",
    "    temp_df[strname]=temp_df[strname].fillna((temp_df[strname].ffill()+\\\n",
    "                                              temp_df[strname].bfill())/2)\n",
    "    insert_lst = temp_df[strname]\n",
    "    pm10_lst.append(insert_lst)\n",
    "    pm25_lst.append(insert_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 12])\n",
      "torch.Size([960, 12])\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# 결측치확인\n",
    "pm10_data = torch.Tensor(np.array(pm10_lst)).T\n",
    "pm25_data = torch.Tensor(np.array(pm25_lst)).T\n",
    "pm10_data = pm10_data[:-2]\n",
    "pm25_data = pm25_data[:-2]\n",
    "print(pm10_data.shape)\n",
    "print(pm25_data.shape)\n",
    "print(pm10_data.isnan().sum())\n",
    "print(pm25_data.isnan().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터세트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index:index+self.seq_length]\n",
    "        y = self.data[index+self.seq_length,:12]\n",
    "        return x, y\n",
    "\n",
    "seq_length = 1\n",
    "\n",
    "# pm10 데이터를 학습, 검증 및 테스트 세트로 나눕니다.\n",
    "pm10_train, temp_data = train_test_split(pm10_data, test_size=0.25, shuffle=False)\n",
    "pm10_valid, pm10_test = train_test_split(temp_data, test_size=0.4, shuffle=False)\n",
    "train_data_loader_pm10 = DataLoader(TimeSeriesDataset(pm10_train, seq_length),\n",
    "                                    batch_size=16, shuffle=True)\n",
    "valid_data_loader_pm10 = DataLoader(TimeSeriesDataset(pm10_valid, seq_length), \n",
    "                                    batch_size=16, shuffle=True)\n",
    "test_data_loader_pm10 = DataLoader(TimeSeriesDataset(pm10_test, seq_length), \n",
    "                                   batch_size=16, shuffle=True)\n",
    "\n",
    "# pm25 데이터를 학습, 검증 및 테스트 세트로 나눕니다.\n",
    "pm25_train, temp_data = train_test_split(pm25_data, test_size=0.25, shuffle=False)\n",
    "pm25_valid, pm25_test = train_test_split(temp_data, test_size=0.4, shuffle=False)\n",
    "train_data_loader_pm25 = DataLoader(TimeSeriesDataset(pm25_train, seq_length), \n",
    "                                    batch_size=16, shuffle=True)\n",
    "valid_data_loader_pm25 = DataLoader(TimeSeriesDataset(pm25_valid, seq_length), \n",
    "                                    batch_size=16, shuffle=True)\n",
    "test_data_loader_pm25 = DataLoader(TimeSeriesDataset(pm25_test, seq_length), \n",
    "                                   batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 16  \n",
    "hidden_size = 64\n",
    "num_layers = 4\n",
    "output_size = 12 \n",
    "\n",
    "model_pm10 = MultiInputOutputLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "model_pm25 = MultiInputOutputLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_pm10 = torch.optim.Adam(model_pm10.parameters(), lr=0.001)\n",
    "optimizer_pm25 = torch.optim.Adam(model_pm25.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 524.5707\n",
      "Epoch [11/1000], Loss: 63.9816\n",
      "Epoch [21/1000], Loss: 96.4349\n",
      "Epoch [31/1000], Loss: 133.0191\n",
      "Epoch [41/1000], Loss: 161.3814\n",
      "Epoch [51/1000], Loss: 73.7318\n",
      "Epoch [61/1000], Loss: 130.2796\n",
      "Epoch [71/1000], Loss: 110.2948\n",
      "Epoch [81/1000], Loss: 63.9729\n",
      "Epoch [91/1000], Loss: 78.9729\n",
      "Epoch [101/1000], Loss: 34.8458\n",
      "Epoch [111/1000], Loss: 44.9871\n",
      "Epoch [121/1000], Loss: 62.3526\n",
      "Epoch [131/1000], Loss: 38.0480\n",
      "Epoch [141/1000], Loss: 55.1448\n",
      "Epoch [151/1000], Loss: 78.5895\n",
      "Epoch [161/1000], Loss: 59.0046\n",
      "Epoch [171/1000], Loss: 39.7374\n",
      "Epoch [181/1000], Loss: 42.4826\n",
      "Epoch [191/1000], Loss: 47.6980\n",
      "Epoch [201/1000], Loss: 64.8528\n",
      "Epoch [211/1000], Loss: 56.5142\n",
      "Epoch [221/1000], Loss: 38.6040\n",
      "Epoch [231/1000], Loss: 38.2021\n",
      "Epoch [241/1000], Loss: 42.4196\n",
      "Epoch [251/1000], Loss: 55.9004\n",
      "Epoch [261/1000], Loss: 51.1525\n",
      "Epoch [271/1000], Loss: 39.3010\n",
      "Epoch [281/1000], Loss: 47.9469\n",
      "Epoch [291/1000], Loss: 40.8767\n",
      "Epoch [301/1000], Loss: 57.1797\n",
      "Epoch [311/1000], Loss: 48.5280\n",
      "Epoch [321/1000], Loss: 30.9784\n",
      "Epoch [331/1000], Loss: 34.7831\n",
      "Epoch [341/1000], Loss: 80.0940\n",
      "Epoch [351/1000], Loss: 47.6749\n",
      "Epoch [361/1000], Loss: 40.3955\n",
      "Epoch [371/1000], Loss: 47.6021\n",
      "Epoch [381/1000], Loss: 42.1288\n",
      "Epoch [391/1000], Loss: 45.6739\n",
      "Epoch [401/1000], Loss: 42.3802\n",
      "Epoch [411/1000], Loss: 37.2794\n",
      "Epoch [421/1000], Loss: 46.5645\n",
      "Epoch [431/1000], Loss: 38.6355\n",
      "Epoch [441/1000], Loss: 47.4965\n",
      "Epoch [451/1000], Loss: 29.1544\n",
      "Epoch [461/1000], Loss: 41.0232\n",
      "Epoch [471/1000], Loss: 54.4827\n",
      "Epoch [481/1000], Loss: 86.4419\n",
      "Epoch [491/1000], Loss: 63.4491\n",
      "Epoch [501/1000], Loss: 42.2670\n",
      "Epoch [511/1000], Loss: 27.4149\n",
      "Epoch [521/1000], Loss: 53.7947\n",
      "Epoch [531/1000], Loss: 32.0438\n",
      "Epoch [541/1000], Loss: 33.5647\n",
      "Epoch [551/1000], Loss: 40.7483\n",
      "Epoch [561/1000], Loss: 44.4249\n",
      "Epoch [571/1000], Loss: 34.1455\n",
      "Epoch [581/1000], Loss: 39.7188\n",
      "Epoch [591/1000], Loss: 23.3340\n",
      "Epoch [601/1000], Loss: 31.8274\n",
      "Epoch [611/1000], Loss: 34.8663\n",
      "Epoch [621/1000], Loss: 30.0920\n",
      "Epoch [631/1000], Loss: 34.6449\n",
      "Epoch [641/1000], Loss: 23.7010\n",
      "Epoch [651/1000], Loss: 35.0909\n",
      "Epoch [661/1000], Loss: 35.4470\n",
      "Epoch [671/1000], Loss: 35.2407\n",
      "Epoch [681/1000], Loss: 29.3948\n",
      "Epoch [691/1000], Loss: 32.4652\n",
      "Epoch [701/1000], Loss: 28.6764\n",
      "Epoch [711/1000], Loss: 34.8823\n",
      "Epoch [721/1000], Loss: 35.2106\n",
      "Epoch [731/1000], Loss: 29.7035\n",
      "Epoch [741/1000], Loss: 34.0520\n",
      "Epoch [751/1000], Loss: 38.6936\n",
      "Epoch [761/1000], Loss: 30.7481\n",
      "Epoch [771/1000], Loss: 99.0192\n",
      "Epoch [781/1000], Loss: 32.6860\n",
      "Epoch [791/1000], Loss: 27.0093\n",
      "Epoch [801/1000], Loss: 41.7665\n",
      "Epoch [811/1000], Loss: 34.1436\n",
      "Epoch [821/1000], Loss: 26.1161\n",
      "Epoch [831/1000], Loss: 24.8738\n",
      "Epoch [841/1000], Loss: 25.8175\n",
      "Epoch [851/1000], Loss: 21.9619\n",
      "Epoch [861/1000], Loss: 19.8259\n",
      "Epoch [871/1000], Loss: 23.0771\n",
      "Epoch [881/1000], Loss: 22.4414\n",
      "Epoch [891/1000], Loss: 19.6760\n",
      "Epoch [901/1000], Loss: 23.7924\n",
      "Epoch [911/1000], Loss: 14.0805\n",
      "Epoch [921/1000], Loss: 25.5855\n",
      "Epoch [931/1000], Loss: 68.7400\n",
      "Epoch [941/1000], Loss: 22.3784\n",
      "Epoch [951/1000], Loss: 16.7267\n",
      "Epoch [961/1000], Loss: 23.7476\n",
      "Epoch [971/1000], Loss: 37.2374\n",
      "Epoch [981/1000], Loss: 25.7839\n",
      "Epoch [991/1000], Loss: 20.9574\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "num_epochs = 1000\n",
    "best_loss = float('inf')  # 초기 최고 손실 설정\n",
    "checkpoint_path_pm10 = 'testweights/pm10/best_model_weights2.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_data_loader_pm10:\n",
    "        inputs, labels = batch\n",
    "        optimizer_pm10.zero_grad()\n",
    "        outputs = model_pm10(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_pm10.step()\n",
    "\n",
    "    # 현재 epoch의 손실값 확인\n",
    "    current_loss = loss.item()\n",
    "    \n",
    "     # 검증 손실 계산\n",
    "    model_pm10.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_data_loader_pm10:\n",
    "            inputs, labels = batch\n",
    "            outputs = model_pm10(inputs)\n",
    "            valid_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    # 검증 손실이 가장 낮을 때 모델 가중치 저장\n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model_pm10.state_dict(), checkpoint_path_pm10)\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 58.8057\n"
     ]
    }
   ],
   "source": [
    "# 테스트 루프\n",
    "input_lst = []\n",
    "label_lst = []\n",
    "pred_lst = []\n",
    "model_pm10.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader_pm10:\n",
    "        inputs, labels = batch\n",
    "        outputs = model_pm10(inputs)\n",
    "        test_loss += criterion(outputs, labels).item()\n",
    "        input_lst.extend(inputs)\n",
    "        label_lst.extend(labels)\n",
    "        pred_lst.extend(outputs)\n",
    "\n",
    "print(f'Test Loss: {test_loss / len(test_data_loader_pm10):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 155.2595\n",
      "Epoch [2/100], Loss: 32.6452\n",
      "Epoch [3/100], Loss: 120.4637\n",
      "Epoch [4/100], Loss: 47.1863\n",
      "Epoch [5/100], Loss: 23.4247\n",
      "Epoch [6/100], Loss: 16.8392\n",
      "Epoch [7/100], Loss: 72.9942\n",
      "Epoch [8/100], Loss: 24.6682\n",
      "Epoch [9/100], Loss: 17.6003\n",
      "Epoch [10/100], Loss: 15.8360\n",
      "Epoch [11/100], Loss: 12.1751\n",
      "Epoch [12/100], Loss: 29.5226\n",
      "Epoch [13/100], Loss: 22.5087\n",
      "Epoch [14/100], Loss: 14.0162\n",
      "Epoch [15/100], Loss: 37.6619\n",
      "Epoch [16/100], Loss: 14.7038\n",
      "Epoch [17/100], Loss: 27.0630\n",
      "Epoch [18/100], Loss: 7.7056\n",
      "Epoch [19/100], Loss: 12.7369\n",
      "Epoch [20/100], Loss: 17.9581\n",
      "Epoch [21/100], Loss: 9.6349\n",
      "Epoch [22/100], Loss: 18.7227\n",
      "Epoch [23/100], Loss: 17.2819\n",
      "Epoch [24/100], Loss: 20.7117\n",
      "Epoch [25/100], Loss: 22.0040\n",
      "Epoch [26/100], Loss: 18.4339\n",
      "Epoch [27/100], Loss: 31.3125\n",
      "Epoch [28/100], Loss: 21.3373\n",
      "Epoch [29/100], Loss: 22.1347\n",
      "Epoch [30/100], Loss: 14.9164\n",
      "Epoch [31/100], Loss: 22.6069\n",
      "Epoch [32/100], Loss: 19.8822\n",
      "Epoch [33/100], Loss: 30.6453\n",
      "Epoch [34/100], Loss: 19.3137\n",
      "Epoch [35/100], Loss: 15.4397\n",
      "Epoch [36/100], Loss: 17.7549\n",
      "Epoch [37/100], Loss: 15.5336\n",
      "Epoch [38/100], Loss: 22.7359\n",
      "Epoch [39/100], Loss: 11.4366\n",
      "Epoch [40/100], Loss: 20.9931\n",
      "Epoch [41/100], Loss: 19.6716\n",
      "Epoch [42/100], Loss: 28.7097\n",
      "Epoch [43/100], Loss: 41.9467\n",
      "Epoch [44/100], Loss: 11.0320\n",
      "Epoch [45/100], Loss: 12.6706\n",
      "Epoch [46/100], Loss: 11.7744\n",
      "Epoch [47/100], Loss: 8.7673\n",
      "Epoch [48/100], Loss: 12.3901\n",
      "Epoch [49/100], Loss: 13.6376\n",
      "Epoch [50/100], Loss: 12.9435\n",
      "Epoch [51/100], Loss: 21.4604\n",
      "Epoch [52/100], Loss: 11.9959\n",
      "Epoch [53/100], Loss: 25.2645\n",
      "Epoch [54/100], Loss: 15.1442\n",
      "Epoch [55/100], Loss: 12.9369\n",
      "Epoch [56/100], Loss: 8.6354\n",
      "Epoch [57/100], Loss: 11.0043\n",
      "Epoch [58/100], Loss: 38.4461\n",
      "Epoch [59/100], Loss: 20.1475\n",
      "Epoch [60/100], Loss: 15.6795\n",
      "Epoch [61/100], Loss: 15.1696\n",
      "Epoch [62/100], Loss: 21.6172\n",
      "Epoch [63/100], Loss: 6.8457\n",
      "Epoch [64/100], Loss: 13.4021\n",
      "Epoch [65/100], Loss: 26.1781\n",
      "Epoch [66/100], Loss: 15.6996\n",
      "Epoch [67/100], Loss: 17.3363\n",
      "Epoch [68/100], Loss: 11.3297\n",
      "Epoch [69/100], Loss: 12.9778\n",
      "Epoch [70/100], Loss: 21.5025\n",
      "Epoch [71/100], Loss: 23.5047\n",
      "Epoch [72/100], Loss: 18.5524\n",
      "Epoch [73/100], Loss: 14.5542\n",
      "Epoch [74/100], Loss: 43.2939\n",
      "Epoch [75/100], Loss: 14.9518\n",
      "Epoch [76/100], Loss: 16.3904\n",
      "Epoch [77/100], Loss: 9.0985\n",
      "Epoch [78/100], Loss: 7.7816\n",
      "Epoch [79/100], Loss: 10.2760\n",
      "Epoch [80/100], Loss: 8.4758\n",
      "Epoch [81/100], Loss: 22.1047\n",
      "Epoch [82/100], Loss: 8.4490\n",
      "Epoch [83/100], Loss: 10.1260\n",
      "Epoch [84/100], Loss: 19.8846\n",
      "Epoch [85/100], Loss: 9.3554\n",
      "Epoch [86/100], Loss: 16.2223\n",
      "Epoch [87/100], Loss: 10.0039\n",
      "Epoch [88/100], Loss: 10.6250\n",
      "Epoch [89/100], Loss: 9.7438\n",
      "Epoch [90/100], Loss: 10.2797\n",
      "Epoch [91/100], Loss: 11.4917\n",
      "Epoch [92/100], Loss: 7.3975\n",
      "Epoch [93/100], Loss: 10.9161\n",
      "Epoch [94/100], Loss: 10.5908\n",
      "Epoch [95/100], Loss: 14.3763\n",
      "Epoch [96/100], Loss: 5.6245\n",
      "Epoch [97/100], Loss: 15.2665\n",
      "Epoch [98/100], Loss: 5.9973\n",
      "Epoch [99/100], Loss: 9.2126\n",
      "Epoch [100/100], Loss: 10.1146\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "num_epochs = 100\n",
    "best_loss = float('inf')  # 초기 최고 손실 설정\n",
    "checkpoint_path_pm25 = 'testweights/pm25/best_model_weights.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_data_loader_pm25:\n",
    "        inputs, labels = batch\n",
    "        optimizer_pm25.zero_grad()\n",
    "        outputs = model_pm25(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_pm25.step()\n",
    "\n",
    "    # 현재 epoch의 손실값 확인\n",
    "    current_loss = loss.item()\n",
    "    \n",
    "     # 검증 손실 계산\n",
    "    model_pm25.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_data_loader_pm25:\n",
    "            inputs, labels = batch\n",
    "            outputs = model_pm25(inputs)\n",
    "            valid_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    # 검증 손실이 가장 낮을 때 모델 가중치 저장\n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model_pm25.state_dict(), checkpoint_path_pm25)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 82.9221\n"
     ]
    }
   ],
   "source": [
    "# 테스트 루프\n",
    "model_pm25.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader_pm25:\n",
    "        inputs, labels = batch\n",
    "        outputs = model_pm25(inputs)\n",
    "        test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "print(f'Test Loss: {test_loss / len(test_data_loader_pm25):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
